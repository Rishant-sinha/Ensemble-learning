{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Learning"
      ],
      "metadata": {
        "id": "8phnnP2ssuww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Can we use Bagging for regression problems?\n",
        "- Yes, bagging can be used for regression problems. In this technique, multiple models are trained on different random subsets of the training data. The final prediction is made by averaging the outputs of all the models. This helps to reduce variance and improve the accuracy of the regression model. Random Forest Regressor is a common example of bagging used for regression.\n"
      ],
      "metadata": {
        "id": "DDmw0VSGszv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  What is the difference between multiple model training and single model training?\n",
        "The difference between **multiple model training** and **single model training** lies in how predictions are generated and how errors are handled:\n",
        "\n",
        " 1. **Single Model Training**:\n",
        "\n",
        "   * Only one model is trained on the entire dataset.\n",
        "   * The prediction depends solely on this model.\n",
        "   * It may have high variance or bias, depending on the model type and data.\n",
        "\n",
        " 2. **Multiple Model Training (Ensemble Methods)**:\n",
        "\n",
        "   * Several models are trained (e.g., on different subsets of data).\n",
        "   * Their predictions are combined (e.g., by voting or averaging).\n",
        "   * It reduces overfitting, increases accuracy, and provides more stable results.\n",
        "\n",
        "In short, **single model = one opinion**, while **multiple models = group decision**.\n"
      ],
      "metadata": {
        "id": "3Og8dUQTtQO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain the concept of feature randomness in Random Forest.\n",
        "- **Feature randomness** in a **Random Forest** refers to the idea of selecting a random subset of features (columns) at each split in a decision tree.\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "* In a Random Forest, multiple decision trees are built.\n",
        "* When a tree decides where to split a node, it doesn't consider all features.\n",
        "* Instead, it randomly selects a subset of features and chooses the best split only from those.\n",
        "\n",
        "### Purpose:\n",
        "\n",
        "* This randomness helps to make each tree different from the others.\n",
        "* It reduces the chance that all trees make the same mistakes.\n",
        "* It leads to better generalization and less overfitting.\n",
        "\n",
        "### Example:\n",
        "\n",
        "If you have 10 features, a Random Forest might use only 3 randomly chosen features to decide each split in each tree.\n",
        "\n",
        "In short, **feature randomness increases diversity among trees**, which improves the overall performance of the forest.\n"
      ],
      "metadata": {
        "id": "e3HWBBQEtmOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is OOB (Out-of-Bag) Score?\n",
        "- The **Out-of-Bag (OOB) score** is a way to measure the performance of a Random Forest model without needing a separate test set. When each tree in the forest is trained, it uses a random subset of the data, and about one-third of the data is left out — this is called the OOB data. The model then tests its predictions on this unused data. The OOB score is the average result of these predictions and gives a good estimate of how well the model will perform on unseen data.\n"
      ],
      "metadata": {
        "id": "8OU4gmJCt9Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "- In a **Random Forest model**, feature importance can be measured by how much each feature contributes to improving the model’s performance. There are two common ways to do this:\n",
        "\n",
        "1. **Gini Importance (Mean Decrease in Impurity)**:\n",
        "\n",
        "   * Every time a feature is used to split a node, the model measures how much the split improves the purity (reduces impurity).\n",
        "   * The improvements are added up and averaged across all trees.\n",
        "   * Features with higher total improvement are considered more important.\n",
        "\n",
        "2. **Permutation Importance**:\n",
        "\n",
        "   * After the model is trained, the values of one feature are randomly shuffled.\n",
        "   * The model's performance is measured again.\n",
        "   * If the performance drops a lot, the feature is important. If not, it’s less important.\n",
        "\n",
        "In simple terms, feature importance tells us **which features help the model make better decisions**.\n"
      ],
      "metadata": {
        "id": "ViyzP8WzuMCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain the working principle of a Bagging Classifier.\n",
        "- The **Bagging Classifier** works by combining the predictions of multiple base classifiers to improve accuracy and reduce overfitting. Here's how it works:\n",
        "\n",
        "1. **Bootstrapping**: It creates multiple random subsets of the original training data by sampling **with replacement** (some data points may repeat).\n",
        "\n",
        "2. **Training**: A separate base model (like a decision tree) is trained on each of these subsets independently.\n",
        "\n",
        "3. **Prediction**:\n",
        "\n",
        "   * For **classification**, each model gives a class prediction, and the final output is decided by **majority voting** (the class that most models predict).\n",
        "   * For **regression**, it takes the **average** of all predictions.\n",
        "\n",
        "4. **Outcome**: This process reduces variance and improves model stability and accuracy, especially for models like decision trees that are sensitive to small changes in the data.\n",
        "\n",
        "In short, a **Bagging Classifier** builds many models on different data samples and combines their outputs to make a stronger overall prediction.\n"
      ],
      "metadata": {
        "id": "uHlteEqGuWhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How do you evaluate a Bagging Classifier’s performance?\n",
        "- You can evaluate a **Bagging Classifier’s** performance using the following methods:\n",
        "\n",
        "1. **Accuracy Score**:\n",
        "\n",
        "   * Measures the percentage of correct predictions on a test set.\n",
        "   * Useful for balanced classification problems.\n",
        "\n",
        "2. **Confusion Matrix**:\n",
        "\n",
        "   * Shows true positives, true negatives, false positives, and false negatives.\n",
        "   * Helps understand model errors in detail.\n",
        "\n",
        "3. **Precision, Recall, and F1-Score**:\n",
        "\n",
        "   * Precision: How many predicted positives are actually correct.\n",
        "   * Recall: How many actual positives were correctly predicted.\n",
        "   * F1-Score: Harmonic mean of precision and recall.\n",
        "\n",
        "4. **ROC Curve and AUC Score**:\n",
        "\n",
        "   * Shows the trade-off between true positive rate and false positive rate.\n",
        "   * AUC (Area Under Curve) gives a single score; closer to 1 is better.\n",
        "\n",
        "5. **Cross-Validation**:\n",
        "\n",
        "   * Splits the data into multiple parts to test the model on different subsets.\n",
        "   * Gives a more reliable estimate of performance.\n",
        "\n",
        "6. **OOB (Out-of-Bag) Score**:\n",
        "\n",
        "   * Specific to Bagging; evaluates accuracy using samples not included in each bootstrap set.\n",
        "\n",
        "In short, performance is checked using accuracy, precision-recall metrics, ROC curves, and possibly the OOB score for internal validation.\n"
      ],
      "metadata": {
        "id": "usmxMOxrukGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. How does a Bagging Regressor work?\n",
        "- A **Bagging Regressor** works by combining the predictions of multiple regression models to improve accuracy and reduce overfitting. Here's how it works:\n",
        "\n",
        "1. **Bootstrapping**:\n",
        "\n",
        "   * It creates multiple random subsets of the training data by sampling **with replacement**.\n",
        "\n",
        "2. **Training**:\n",
        "\n",
        "   * A separate **regression model** (usually decision trees) is trained on each subset independently.\n",
        "\n",
        "3. **Prediction**:\n",
        "\n",
        "   * Each model makes a numerical prediction.\n",
        "   * The final output is the **average** of all these predictions.\n",
        "\n",
        "4. **Result**:\n",
        "\n",
        "   * Averaging reduces the model's **variance**, leading to more stable and accurate predictions.\n",
        "\n",
        "In short, a **Bagging Regressor** builds several models on different data samples and **averages** their outputs to get a stronger, more reliable prediction.\n"
      ],
      "metadata": {
        "id": "p2gKixvruy-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main advantage of ensemble techniques?\n",
        "- The main advantage of ensemble techniques is that they **combine multiple models to produce better overall performance** than any single model alone. This leads to:\n",
        "\n",
        "* **Higher accuracy**\n",
        "* **Reduced overfitting**\n",
        "* **Improved robustness and stability**\n",
        "* Better generalization to new, unseen data.\n",
        "\n",
        "In short, ensembles leverage the strengths of many models to make more reliable and accurate predictions.\n"
      ],
      "metadata": {
        "id": "u0wdK9-Qu-Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What is the main challenge of ensemble methods?\n",
        "- The main challenge of ensemble methods is that they can be **computationally expensive and complex**. Training multiple models requires more time, memory, and processing power compared to a single model. Additionally, ensembles can be harder to interpret and explain, making it difficult to understand how individual features influence the final prediction.\n"
      ],
      "metadata": {
        "id": "bGBVwDsvvIuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Explain the key idea behind ensemble techniques.\n",
        "- The key idea behind ensemble techniques is to combine the predictions of multiple models to create a stronger overall model. By aggregating different models—each trained in slightly different ways—ensembles reduce errors like bias and variance. This leads to more accurate, stable, and reliable predictions than any single model could achieve alone. Essentially, ensembles use the “wisdom of the crowd” to improve performance.\n"
      ],
      "metadata": {
        "id": "wyBAyaUDvR2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. What is a Random Forest Classifier?\n",
        "- A **Random Forest Classifier** is an ensemble learning method that builds many decision trees during training and combines their predictions to classify data. Each tree is trained on a random subset of the data (bootstrapped samples) and, at each split, considers a random subset of features. The final class prediction is made by **majority voting** across all the trees. This approach improves accuracy, reduces overfitting, and increases model robustness compared to a single decision tree.\n"
      ],
      "metadata": {
        "id": "Wldwzt8evZjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are the main types of ensemble techniques?\n",
        "- The main types of ensemble techniques are:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating)**\n",
        "\n",
        "   * Builds multiple models independently on different random samples of the data.\n",
        "   * Combines predictions by voting (classification) or averaging (regression).\n",
        "   * Example: Random Forest.\n",
        "\n",
        "2. **Boosting**\n",
        "\n",
        "   * Builds models sequentially, where each model tries to correct the errors of the previous one.\n",
        "   * Focuses more on difficult cases.\n",
        "   * Example: AdaBoost, Gradient Boosting.\n",
        "\n",
        "3. **Stacking (Stacked Generalization)**\n",
        "\n",
        "   * Combines multiple different models by training a “meta-model” on their outputs.\n",
        "   * The meta-model learns how to best combine predictions.\n",
        "\n",
        "4. **Voting**\n",
        "\n",
        "   * Combines predictions of multiple models by majority vote (hard voting) or averaging predicted probabilities (soft voting).\n",
        "\n",
        "These techniques improve prediction accuracy by leveraging multiple models in different ways.\n"
      ],
      "metadata": {
        "id": "F4bBHW-KvhiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is ensemble learning in machine learning?\n",
        "- **Ensemble learning** in machine learning is a technique where multiple models (often called “weak learners”) are combined to solve a problem and improve overall performance. Instead of relying on a single model, ensemble learning aggregates the predictions of several models to get more accurate, stable, and reliable results. The idea is that a group of models working together can outperform any individual model by reducing errors like bias and variance.\n"
      ],
      "metadata": {
        "id": "YHsoMTHLvr8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. When should we avoid using ensemble methods?\n",
        "- We should avoid using ensemble methods when:\n",
        "\n",
        "1. **Interpretability is critical** — ensembles are harder to explain than simple models.\n",
        "2. **Computational resources are limited** — training many models takes more time and memory.\n",
        "3. **The dataset is very small** — ensembles can overfit or not add much benefit.\n",
        "4. **A single simple model already performs well** — adding complexity may not improve results much.\n",
        "5. **Real-time predictions are needed** — ensembles can be slower to predict.\n",
        "\n",
        "In these cases, simpler models might be a better choice.\n"
      ],
      "metadata": {
        "id": "Upu1oLTNv0rD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. How does Bagging help in reducing overfitting?\n",
        "- Bagging helps reduce overfitting by training multiple models on different random subsets of the data, which introduces diversity among them. Since each model sees slightly different data, their errors tend to be uncorrelated. When their predictions are combined (by voting or averaging), the overall model averages out individual mistakes, reducing variance and preventing the model from fitting noise in the training data too closely. This leads to a more stable and generalized model.\n"
      ],
      "metadata": {
        "id": "qgDK1L1_v-9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. Why is Random Forest better than a single Decision Tree?\n",
        "- Random Forest is better than a single Decision Tree because it builds many trees using different random samples of data and random subsets of features, which creates diversity among the trees. By combining their predictions through majority voting, it reduces overfitting and variance that a single tree often suffers from. This makes Random Forest more accurate, stable, and better at generalizing to new data than a single Decision Tree.\n"
      ],
      "metadata": {
        "id": "eaU5w9tYwHuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What is the role of bootstrap sampling in Bagging?\n",
        "- The role of **bootstrap sampling** in Bagging is to create multiple different training datasets by randomly sampling the original data **with replacement**. Each bootstrap sample is used to train a separate model. This randomness ensures that each model sees a slightly different dataset, which increases diversity among models. When their predictions are combined, this diversity helps reduce variance and overfitting, leading to better overall performance.\n"
      ],
      "metadata": {
        "id": "uTQ0uoKKwQWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. What are some real-world applications of ensemble techniques?\n",
        "- Some real-world applications of ensemble techniques include:\n",
        "\n",
        "1. **Fraud Detection** in banking and finance — ensembles improve accuracy in spotting fraudulent transactions.\n",
        "2. **Medical Diagnosis** — combining models helps in better disease prediction and risk assessment.\n",
        "3. **Spam Filtering** — ensembles classify emails more reliably as spam or not.\n",
        "4. **Customer Churn Prediction** — businesses use ensembles to predict which customers might leave.\n",
        "5. **Image and Speech Recognition** — ensembles boost accuracy in identifying objects or speech patterns.\n",
        "6. **Stock Market Prediction** — combining models helps forecast price movements more robustly.\n",
        "7. **Recommendation Systems** — ensembles enhance product or content recommendations by aggregating multiple models.\n",
        "\n",
        "Ensemble methods are widely used wherever high accuracy and reliability are crucial.\n"
      ],
      "metadata": {
        "id": "1ncigo1_wYEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. What is the difference between Bagging and Boosting.\n",
        "- The key differences between **Bagging** and **Boosting** are:\n",
        "\n",
        "1. **Training Approach:**\n",
        "\n",
        "   * **Bagging** trains multiple models **independently** on random bootstrapped samples of the data.\n",
        "   * **Boosting** trains models **sequentially**, where each new model focuses on correcting the errors of the previous ones.\n",
        "\n",
        "2. **Goal:**\n",
        "\n",
        "   * Bagging mainly **reduces variance** and prevents overfitting by averaging many models.\n",
        "   * Boosting mainly **reduces bias** by combining weak learners to create a strong learner.\n",
        "\n",
        "3. **Model Weighting:**\n",
        "\n",
        "   * In Bagging, all models have **equal weight** in the final prediction.\n",
        "   * In Boosting, models are **weighted** based on their performance.\n",
        "\n",
        "4. **Error Handling:**\n",
        "\n",
        "   * Bagging treats all data points equally.\n",
        "   * Boosting gives more importance to misclassified or hard-to-predict samples.\n",
        "\n",
        "In short, Bagging builds models in parallel to reduce variance, while Boosting builds models sequentially to reduce bias.\n"
      ],
      "metadata": {
        "id": "-XSGi0ftwhdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize base classifier\n",
        "base_clf = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize Bagging Classifier with Decision Trees\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_clf = BaggingClassifier(estimator=base_clf, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEVuOpKbwzSD",
        "outputId": "3bd34cc3-1ac0-41fe-b384-be7bc892317f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "# Updated import to fetch_california_housing as load_boston is deprecated\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset - Using California housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize base regressor\n",
        "base_reg = DecisionTreeRegressor()\n",
        "\n",
        "# Initialize Bagging Regressor\n",
        "# base_estimator is still valid in BaggingRegressor as of scikit-learn 1.3.2\n",
        "# Corrected parameter name from 'base_estimator' to 'estimator'\n",
        "bagging_reg = BaggingRegressor(estimator=base_reg, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Bagging Regressor Mean Squared Error: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AFC0b3DxdR4",
        "outputId": "56ea87df-8476-4529-f4bc-84e88fb02e64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor Mean Squared Error: 0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# Print feature importance with feature names\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6llTbney_jn",
        "outputId": "0e8f9ab9-d113-48c5-b591-fbb6a5190bff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean radius: 0.0323\n",
            "mean texture: 0.0111\n",
            "mean perimeter: 0.0601\n",
            "mean area: 0.0538\n",
            "mean smoothness: 0.0062\n",
            "mean compactness: 0.0092\n",
            "mean concavity: 0.0806\n",
            "mean concave points: 0.1419\n",
            "mean symmetry: 0.0033\n",
            "mean fractal dimension: 0.0031\n",
            "radius error: 0.0164\n",
            "texture error: 0.0032\n",
            "perimeter error: 0.0118\n",
            "area error: 0.0295\n",
            "smoothness error: 0.0059\n",
            "compactness error: 0.0046\n",
            "concavity error: 0.0058\n",
            "concave points error: 0.0034\n",
            "symmetry error: 0.0040\n",
            "fractal dimension error: 0.0071\n",
            "worst radius: 0.0780\n",
            "worst texture: 0.0188\n",
            "worst perimeter: 0.0743\n",
            "worst area: 0.1182\n",
            "worst smoothness: 0.0118\n",
            "worst compactness: 0.0175\n",
            "worst concavity: 0.0411\n",
            "worst concave points: 0.1271\n",
            "worst symmetry: 0.0129\n",
            "worst fractal dimension: 0.0069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train models\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_dt = dt_reg.predict(X_test)\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Decision Tree MSE: {mse_dt:.4f}\")\n",
        "print(f\"Random Forest MSE: {mse_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNz3ysqtzMou",
        "outputId": "7d790272-8ffa-47ac-e52d-ecebb059ed81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 0.5280\n",
            "Random Forest MSE: 0.2565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data (optional, OOB score doesn't require separate test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Random Forest with OOB enabled\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "\n",
        "# Train the model on training data\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Print OOB score\n",
        "print(f\"OOB Score: {rf_clf.oob_score_:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSxuUfWyzeiy",
        "outputId": "096b2b42-ea06-4d1c-8f01-38cae599024b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB Score: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize base estimator (SVM)\n",
        "base_svm = SVC(probability=True, kernel='rbf', random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with SVM base estimator\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_svm = BaggingClassifier(estimator=base_svm, n_estimators=20, random_state=42) # Changed base_estimator to estimator\n",
        "\n",
        "# Train the model\n",
        "bagging_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bagging_svm.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier with SVM Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUrNM7Aozn6-",
        "outputId": "9957c816-74c6-4c29-f869-c1fea0ab7e46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier with SVM Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Different numbers of trees to try\n",
        "n_trees_list = [5, 10, 50, 100, 200]\n",
        "\n",
        "for n_trees in n_trees_list:\n",
        "    # Initialize Random Forest\n",
        "    rf_clf = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
        "\n",
        "    # Train\n",
        "    rf_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Number of Trees: {n_trees} - Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne5BmvY2z5qe",
        "outputId": "9769de56-c352-4969-eade-b46fc2a8d740"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Trees: 5 - Accuracy: 1.0000\n",
            "Number of Trees: 10 - Accuracy: 1.0000\n",
            "Number of Trees: 50 - Accuracy: 1.0000\n",
            "Number of Trees: 100 - Accuracy: 1.0000\n",
            "Number of Trees: 200 - Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# For AUC, convert to binary classification (e.g., class 0 vs rest)\n",
        "# We binarize for one class vs the rest, which is suitable for standard AUC\n",
        "# For multi-class AUC, you would need a different approach (e.g., one-vs-rest or one-vs-one)\n",
        "# For simplicity here, we focus on class 0 vs others.\n",
        "y_binary = (y == 0).astype(int)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
        "\n",
        "# Base estimator: Logistic Regression\n",
        "# Increased max_iter to ensure convergence\n",
        "base_lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
        "\n",
        "# Bagging Classifier\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_lr = BaggingClassifier(estimator=base_lr, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train\n",
        "bagging_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "# Get probability of the positive class (class 1 in y_binary, which corresponds to class 0 in original y)\n",
        "y_prob = bagging_lr.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate AUC score\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"Bagging Classifier with Logistic Regression AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBqhDfwI0EUf",
        "outputId": "d3403803-7f7d-4cac-deaf-f2cc642913f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier with Logistic Regression AUC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29.  Train a Random Forest Regressor and analyze feature importance scores.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_reg.feature_importances_\n",
        "\n",
        "# Print feature importance with feature names\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"{name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrEUlKkS0mYc",
        "outputId": "f8b542c4-3495-488d-c39e-ba1b31b81c95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedInc: 0.5260\n",
            "HouseAge: 0.0547\n",
            "AveRooms: 0.0472\n",
            "AveBedrms: 0.0300\n",
            "Population: 0.0317\n",
            "AveOccup: 0.1382\n",
            "Latitude: 0.0861\n",
            "Longitude: 0.0861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize base estimator for bagging\n",
        "base_dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Bagging Classifier\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_clf = BaggingClassifier(estimator=base_dt, n_estimators=50, random_state=42) # Corrected parameter name\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re0l88yq00gX",
        "outputId": "a790732b-95de-47ed-9761-c37d359b7c9a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0000\n",
            "Random Forest Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict using best estimator\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with Best Params: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGQ5otUG1Fmd",
        "outputId": "fcd75db4-45e7-40bc-ffbd-fa4ef09ba37d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Best Hyperparameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Accuracy with Best Params: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "180 fits failed out of a total of 360.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93333333 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
            " 0.94285714 0.93333333 0.93333333 0.93333333 0.93333333 0.93333333\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93333333 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
            " 0.94285714 0.93333333 0.93333333 0.93333333 0.93333333 0.93333333\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.93333333 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
            " 0.94285714 0.93333333 0.93333333 0.93333333 0.93333333 0.93333333]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Different numbers of base estimators to try\n",
        "n_estimators_list = [5, 10, 50, 100]\n",
        "\n",
        "for n in n_estimators_list:\n",
        "    # Initialize Bagging Regressor\n",
        "    # Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    print(f\"Number of Estimators: {n} - MSE: {mse:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrxfSik91arW",
        "outputId": "4e41bb64-ad71-4dc7-848b-9a9ffaead5e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Estimators: 5 - MSE: 0.3168\n",
            "Number of Estimators: 10 - MSE: 0.2862\n",
            "Number of Estimators: 50 - MSE: 0.2579\n",
            "Number of Estimators: 100 - MSE: 0.2568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33.  Train a Random Forest Classifier and analyze misclassified samples.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Find misclassified samples\n",
        "misclassified_indices = np.where(y_pred != y_test)[0]\n",
        "\n",
        "print(f\"Number of misclassified samples: {len(misclassified_indices)}\")\n",
        "print(\"Misclassified samples (index in test set, true label, predicted label):\")\n",
        "\n",
        "for idx in misclassified_indices:\n",
        "    print(f\"Index: {idx}, True: {y_test[idx]}, Predicted: {y_pred[idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AapXdDTa15Ou",
        "outputId": "e69b5111-f58d-47b3-a652-d18b9350b376"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of misclassified samples: 0\n",
            "Misclassified samples (index in test set, true label, predicted label):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Single Decision Tree\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Bagging Classifier with Decision Trees\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42) # Corrected parameter name\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSXfRHzR2Jhf",
        "outputId": "12debae8-03b6-4a73-dabf-3408beb7611d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 1.0000\n",
            "Bagging Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SlK6j-Kh2bGa",
        "outputId": "810f53a5-9af7-417a-fb79-63defc98cee1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Base learners\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Stacking Classifier with Logistic Regression as final estimator\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Stacking Classifier\n",
        "y_pred_stack = stacking_clf.predict(X_test)\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "\n",
        "print(f\"Stacking Classifier Accuracy: {acc_stack:.4f}\")\n",
        "\n",
        "# Optionally, compare with individual base learners\n",
        "for name, model in estimators:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8jrxTKP2mlK",
        "outputId": "b04a9dc1-1581-4e12-8f80-98d7b0962674"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0000\n",
            "dt Accuracy: 1.0000\n",
            "svm Accuracy: 1.0000\n",
            "lr Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "# Get indices of top 5 features\n",
        "top5_idx = np.argsort(importances)[::-1][:5]\n",
        "\n",
        "print(\"Top 5 important features:\")\n",
        "for i in top5_idx:\n",
        "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZXiHMuJ2xmU",
        "outputId": "825b50e9-f6fe-4b5c-8686-8e1e48037ce0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 important features:\n",
            "petal width (cm): 0.4340\n",
            "petal length (cm): 0.4173\n",
            "sepal length (cm): 0.1041\n",
            "sepal width (cm): 0.0446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38 Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize Bagging Classifier with Decision Trees\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42) # Corrected parameter name\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance (average='macro' for multi-class)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtQZW8a026_0",
        "outputId": "d3c5ac67-761c-4a7b-ef96-e695dc59167a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0000\n",
            "Recall:    1.0000\n",
            "F1-score:  1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Test different max_depth values\n",
        "max_depth_values = [None, 2, 4, 6, 8, 10]\n",
        "\n",
        "for depth in max_depth_values:\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"max_depth={depth}: Accuracy = {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbZjLTHy3JF6",
        "outputId": "ab713ece-8b3c-4e23-b9fd-20478fa599e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth=None: Accuracy = 1.0000\n",
            "max_depth=2: Accuracy = 1.0000\n",
            "max_depth=4: Accuracy = 1.0000\n",
            "max_depth=6: Accuracy = 1.0000\n",
            "max_depth=8: Accuracy = 1.0000\n",
            "max_depth=10: Accuracy = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Bagging with Decision Tree base estimator\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_dt = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
        "bagging_dt.fit(X_train, y_train)\n",
        "y_pred_dt = bagging_dt.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "\n",
        "# Bagging with KNeighbors base estimator\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_knn = BaggingRegressor(estimator=KNeighborsRegressor(), n_estimators=50, random_state=42)\n",
        "bagging_knn.fit(X_train, y_train)\n",
        "y_pred_knn = bagging_knn.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "\n",
        "print(f\"Bagging with Decision Tree MSE: {mse_dt:.4f}\")\n",
        "print(f\"Bagging with KNeighbors MSE:    {mse_knn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LIjBR7x3Tq0",
        "outputId": "f53281c2-a17c-4738-cdc5-38d7b6d38aea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging with Decision Tree MSE: 0.2579\n",
            "Bagging with KNeighbors MSE:    1.1021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for positive class\n",
        "y_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GgdGKn93n18",
        "outputId": "48f85340-708f-4c0d-e342-6b00a87b973b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42.Train a Bagging Classifier and evaluate its performance using cross-validatio.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Initialize Bagging Classifier with Decision Trees\n",
        "# Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f\"Cross-validation accuracy scores: {scores}\")\n",
        "print(f\"Mean accuracy: {scores.mean():.4f}\")\n",
        "print(f\"Standard deviation: {scores.std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62iKgLXr3yvE",
        "outputId": "3fd1c04f-1753-4b20-f1fc-bc13673789c6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation accuracy scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean accuracy: 0.9667\n",
            "Standard deviation: 0.0211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for positive class\n",
        "y_scores = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Compute area under curve (AUC) for PR curve\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "# Plot Precision-Recall curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall, precision, label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "pLQXQoEe4Ecj",
        "outputId": "b0be40e2-edd9-4d37-e0c8-a2dfe5c133e9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Initialize Stacking Classifier with Logistic Regression as final estimator\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate Stacking Classifier\n",
        "y_pred_stack = stacking_clf.predict(X_test)\n",
        "acc_stack = accuracy_score(y_test, y_pred_stack)\n",
        "print(f\"Stacking Classifier Accuracy: {acc_stack:.4f}\")\n",
        "\n",
        "# Evaluate individual base models\n",
        "for name, model in estimators:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_BN-8cq4PKy",
        "outputId": "ef762975-ea39-4c6e-ae94-2100ec65dc2f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0000\n",
            "rf Accuracy: 1.0000\n",
            "lr Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Different bootstrap sample sizes (fractions)\n",
        "bootstrap_samples = [0.3, 0.5, 0.7, 1.0]\n",
        "\n",
        "for sample_frac in bootstrap_samples:\n",
        "    # Changed 'base_estimator' to 'estimator' for compatibility with newer scikit-learn versions\n",
        "    bagging_reg = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(), # Corrected parameter name\n",
        "        n_estimators=50,\n",
        "        max_samples=sample_frac,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"max_samples={sample_frac}: MSE = {mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOOYd4Z_4aDK",
        "outputId": "8357a76f-e6fa-4745-92ab-e075902d2883"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_samples=0.3: MSE = 0.2816\n",
            "max_samples=0.5: MSE = 0.2633\n",
            "max_samples=0.7: MSE = 0.2621\n",
            "max_samples=1.0: MSE = 0.2579\n"
          ]
        }
      ]
    }
  ]
}